{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Week 3 Lab: Data Wrangling with Pandas\n",
    "\n",
    "**Estimated Time:** 30-60 minutes  \n",
    "**Objective:** Master essential data cleaning and manipulation techniques using Philippine datasets.\n",
    "\n",
    "In this lab, you will:\n",
    "- Handle missing data appropriately\n",
    "- Clean and transform messy datasets\n",
    "- Merge and join multiple data sources\n",
    "- Work with Philippine census and economic data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell first to import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Handling Missing Data\n",
    "\n",
    "**Background:** Real-world datasets often have missing values. Let's work with Philippine regional population data with incomplete records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Identify Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Philippine regional data with missing values\n",
    "data = {\n",
    "    'Region': ['NCR', 'CAR', 'Region I', 'Region II', 'Region III', 'Region IV-A', 'Region V', 'Region VI'],\n",
    "    'Population': [13484462, 1797660, None, 3685744, 12422172, 16195042, None, 7954723],\n",
    "    'Poverty_Rate': [4.9, 24.6, 15.3, None, 7.8, 6.5, 20.4, 18.3],\n",
    "    'Literacy_Rate': [99.2, 94.3, 97.8, 96.5, None, 98.9, 96.2, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# TODO: Check for missing values - count per column\n",
    "missing_counts = None  # Your code here (use .isnull() or .isna())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# TODO: Calculate percentage of missing values per column\n",
    "missing_percentage = None  # Your code here\n",
    "\n",
    "print(\"\\nMissing percentage per column:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Handle Missing Data\n",
    "\n",
    "Different strategies for different situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Fill missing Population values with the mean population\ndf_filled = df.copy()\n# Your code here (use .fillna() with the mean)\n\n# TODO: Fill missing Poverty_Rate with median\n# Your code here\n\n# TODO: Fill missing Literacy_Rate with forward fill method\n# Your code here (use .ffill())\n\nprint(\"DataFrame after handling missing values:\")\nprint(df_filled)\n\n# Verify no missing values remain\nprint(\"\\nRemaining missing values:\", df_filled.isnull().sum().sum())"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Cleaning\n",
    "\n",
    "**Background:** Data often comes in messy formats. Let's clean Philippine student enrollment data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Clean Messy String Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy university data\n",
    "messy_data = {\n",
    "    'University': ['  UP DILIMAN  ', 'up cebu', 'ATENEO DE MANILA', '  De La Salle  ', 'UST'],\n",
    "    'Students': ['23,000', '4,500', '12000', '  15,000  ', '40000'],\n",
    "    'Type': ['Public', 'PUBLIC', 'private', 'Private', 'PRIVATE']\n",
    "}\n",
    "\n",
    "messy_df = pd.DataFrame(messy_data)\n",
    "print(\"Messy DataFrame:\")\n",
    "print(messy_df)\n",
    "\n",
    "# TODO: Clean University column - strip whitespace and title case\n",
    "messy_df['University'] = None  # Your code here (use .str.strip() and .str.title())\n",
    "\n",
    "# TODO: Convert Students to numeric (remove commas first)\n",
    "# Your code here (use .str.replace() and pd.to_numeric())\n",
    "\n",
    "# TODO: Standardize Type column to capitalize properly\n",
    "messy_df['Type'] = None  # Your code here (use .str.capitalize())\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(messy_df)\n",
    "print(\"\\nData types:\")\n",
    "print(messy_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with duplicates\n",
    "duplicate_data = {\n",
    "    'City': ['Manila', 'Quezon City', 'Manila', 'Cebu City', 'Davao', 'Quezon City'],\n",
    "    'Region': ['NCR', 'NCR', 'NCR', 'Region VII', 'Region XI', 'NCR'],\n",
    "    'Population': [1780000, 2960000, 1780000, 960000, 1780000, 2960000]\n",
    "}\n",
    "\n",
    "dup_df = pd.DataFrame(duplicate_data)\n",
    "print(\"DataFrame with duplicates:\")\n",
    "print(dup_df)\n",
    "\n",
    "# TODO: Check for duplicate rows\n",
    "print(f\"\\nNumber of duplicate rows: {None}\")  # Your code here (use .duplicated().sum())\n",
    "\n",
    "# TODO: Remove duplicate rows\n",
    "clean_df = None  # Your code here (use .drop_duplicates())\n",
    "\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Merging and Joining Datasets\n",
    "\n",
    "**Background:** Combine multiple data sources to create comprehensive datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City population data\n",
    "population_df = pd.DataFrame({\n",
    "    'City': ['Manila', 'Quezon City', 'Caloocan', 'Davao', 'Cebu City'],\n",
    "    'Population': [1780000, 2960000, 1660000, 1780000, 960000]\n",
    "})\n",
    "\n",
    "# City economic data\n",
    "income_df = pd.DataFrame({\n",
    "    'City': ['Manila', 'Quezon City', 'Cebu City', 'Makati', 'Davao'],\n",
    "    'Avg_Income': [35000, 32000, 28000, 55000, 30000]\n",
    "})\n",
    "\n",
    "print(\"Population DataFrame:\")\n",
    "print(population_df)\n",
    "print(\"\\nIncome DataFrame:\")\n",
    "print(income_df)\n",
    "\n",
    "# TODO: Perform inner join on City\n",
    "inner_merged = None  # Your code here (use pd.merge() with how='inner')\n",
    "\n",
    "print(\"\\nInner Join Result (only matching cities):\")\n",
    "print(inner_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform left join (keep all cities from population_df)\n",
    "left_merged = None  # Your code here (use pd.merge() with how='left')\n",
    "\n",
    "print(\"Left Join Result (all population cities):\")\n",
    "print(left_merged)\n",
    "\n",
    "# TODO: Fill missing income values with 0\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nAfter filling missing values:\")\n",
    "print(left_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Concatenate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional data from different sources\n",
    "luzon_data = pd.DataFrame({\n",
    "    'Region': ['NCR', 'Region III', 'Region IV-A'],\n",
    "    'Population': [13484462, 12422172, 16195042],\n",
    "    'Island_Group': ['Luzon', 'Luzon', 'Luzon']\n",
    "})\n",
    "\n",
    "visayas_data = pd.DataFrame({\n",
    "    'Region': ['Region VI', 'Region VII', 'Region VIII'],\n",
    "    'Population': [7954723, 8081988, 4547150],\n",
    "    'Island_Group': ['Visayas', 'Visayas', 'Visayas']\n",
    "})\n",
    "\n",
    "# TODO: Concatenate the two DataFrames vertically\n",
    "combined_df = None  # Your code here (use pd.concat())\n",
    "\n",
    "# TODO: Reset the index\n",
    "# Your code here (use .reset_index(drop=True))\n",
    "\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Advanced Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Creating New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Philippine city data\n",
    "city_df = pd.DataFrame({\n",
    "    'City': ['Manila', 'Quezon City', 'Caloocan', 'Davao'],\n",
    "    'Population': [1780000, 2960000, 1660000, 1780000],\n",
    "    'Area_km2': [42.88, 161.11, 53.33, 2443.61]\n",
    "})\n",
    "\n",
    "# TODO: Create a population density column (Population / Area)\n",
    "city_df['Density'] = None  # Your code here\n",
    "\n",
    "# TODO: Create a category column based on population\n",
    "# Large: > 2M, Medium: 1M-2M, Small: < 1M\n",
    "def categorize_population(pop):\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "city_df['Size_Category'] = None  # Your code here (use .apply())\n",
    "\n",
    "print(\"DataFrame with new columns:\")\n",
    "print(city_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional GDP data\n",
    "gdp_data = pd.DataFrame({\n",
    "    'Region': ['NCR', 'NCR', 'NCR', 'Region VII', 'Region VII', 'Region XI', 'Region XI'],\n",
    "    'Year': [2020, 2021, 2022, 2020, 2021, 2020, 2021],\n",
    "    'GDP_Billion': [6200, 6450, 6800, 1100, 1150, 850, 900]\n",
    "})\n",
    "\n",
    "print(\"GDP Data:\")\n",
    "print(gdp_data)\n",
    "\n",
    "# TODO: Calculate average GDP per region\n",
    "avg_gdp = None  # Your code here (use .groupby() and .mean())\n",
    "\n",
    "print(\"\\nAverage GDP by Region:\")\n",
    "print(avg_gdp)\n",
    "\n",
    "# TODO: Find the total GDP per region across all years\n",
    "total_gdp = None  # Your code here\n",
    "\n",
    "print(\"\\nTotal GDP by Region:\")\n",
    "print(total_gdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection Questions\n",
    "\n",
    "Answer these questions in the cells below:\n",
    "\n",
    "1. **Missing Data Strategy:** When would you choose to drop missing values versus filling them? What are the trade-offs?\n",
    "\n",
    "2. **Data Cleaning Impact:** Why is data cleaning crucial before analysis? Give an example of how messy data could lead to wrong conclusions.\n",
    "\n",
    "3. **Merging Strategies:** Explain the difference between inner join, left join, and outer join. When would you use each?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Your Answer to Question 1:\n",
    "\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "### Your Answer to Question 2:\n",
    "\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Your Answer to Question 3:\n",
    "\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Congratulations!\n",
    "\n",
    "You've completed Week 3 Lab on Data Wrangling with Pandas.\n",
    "\n",
    "**Key Skills Practiced:**\n",
    "- Identifying and handling missing data\n",
    "- Cleaning messy string and numeric data\n",
    "- Removing duplicates\n",
    "- Merging and joining multiple datasets\n",
    "- Creating derived columns and aggregations\n",
    "\n",
    "**Remember:** Check the **solution notebook** if you need help!\n",
    "\n",
    "**Next Steps:**\n",
    "- Practice with more complex Philippine datasets\n",
    "- Explore advanced Pandas functions\n",
    "- Move on to Week 4 lab (Exploratory Data Analysis)\n",
    "\n",
    "---\n",
    "\n",
    "*CMSC 178DA - Data Analytics | University of the Philippines Cebu*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}