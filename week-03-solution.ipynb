{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Week 3 Lab: Data Wrangling with Pandas - SOLUTION\n",
    "\n",
    "**Complete solution notebook with working code for all exercises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Part 1: Handling Missing Data - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Region': ['NCR', 'CAR', 'Region I', 'Region II', 'Region III', 'Region IV-A', 'Region V', 'Region VI'],\n",
    "    'Population': [13484462, 1797660, None, 3685744, 12422172, 16195042, None, 7954723],\n",
    "    'Poverty_Rate': [4.9, 24.6, 15.3, None, 7.8, 6.5, 20.4, 18.3],\n",
    "    'Literacy_Rate': [99.2, 94.3, 97.8, 96.5, None, 98.9, 96.2, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# SOLUTION: Check for missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# SOLUTION: Calculate percentage\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"\\nMissing percentage per column:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# SOLUTION: Handle missing data\ndf_filled = df.copy()\n\n# Fill Population with mean\ndf_filled['Population'] = df_filled['Population'].fillna(df_filled['Population'].mean())\n\n# Fill Poverty_Rate with median\ndf_filled['Poverty_Rate'] = df_filled['Poverty_Rate'].fillna(df_filled['Poverty_Rate'].median())\n\n# Fill Literacy_Rate with forward fill\ndf_filled['Literacy_Rate'] = df_filled['Literacy_Rate'].ffill()\n\nprint(\"DataFrame after handling missing values:\")\nprint(df_filled)\nprint(\"\\nRemaining missing values:\", df_filled.isnull().sum().sum())"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Clean messy string data\n",
    "messy_data = {\n",
    "    'University': ['  UP DILIMAN  ', 'up cebu', 'ATENEO DE MANILA', '  De La Salle  ', 'UST'],\n",
    "    'Students': ['23,000', '4,500', '12000', '  15,000  ', '40000'],\n",
    "    'Type': ['Public', 'PUBLIC', 'private', 'Private', 'PRIVATE']\n",
    "}\n",
    "\n",
    "messy_df = pd.DataFrame(messy_data)\n",
    "print(\"Messy DataFrame:\")\n",
    "print(messy_df)\n",
    "\n",
    "# Clean University\n",
    "messy_df['University'] = messy_df['University'].str.strip().str.title()\n",
    "\n",
    "# Convert Students to numeric\n",
    "messy_df['Students'] = messy_df['Students'].str.replace(',', '').str.strip()\n",
    "messy_df['Students'] = pd.to_numeric(messy_df['Students'])\n",
    "\n",
    "# Standardize Type\n",
    "messy_df['Type'] = messy_df['Type'].str.capitalize()\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(messy_df)\n",
    "print(\"\\nData types:\")\n",
    "print(messy_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Handle duplicates\n",
    "duplicate_data = {\n",
    "    'City': ['Manila', 'Quezon City', 'Manila', 'Cebu City', 'Davao', 'Quezon City'],\n",
    "    'Region': ['NCR', 'NCR', 'NCR', 'Region VII', 'Region XI', 'NCR'],\n",
    "    'Population': [1780000, 2960000, 1780000, 960000, 1780000, 2960000]\n",
    "}\n",
    "\n",
    "dup_df = pd.DataFrame(duplicate_data)\n",
    "print(\"DataFrame with duplicates:\")\n",
    "print(dup_df)\n",
    "\n",
    "print(f\"\\nNumber of duplicate rows: {dup_df.duplicated().sum()}\")\n",
    "\n",
    "clean_df = dup_df.drop_duplicates()\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 3: Merging and Joining - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Inner join\n",
    "population_df = pd.DataFrame({\n",
    "    'City': ['Manila', 'Quezon City', 'Caloocan', 'Davao', 'Cebu City'],\n",
    "    'Population': [1780000, 2960000, 1660000, 1780000, 960000]\n",
    "})\n",
    "\n",
    "income_df = pd.DataFrame({\n",
    "    'City': ['Manila', 'Quezon City', 'Cebu City', 'Makati', 'Davao'],\n",
    "    'Avg_Income': [35000, 32000, 28000, 55000, 30000]\n",
    "})\n",
    "\n",
    "print(\"Population DataFrame:\")\n",
    "print(population_df)\n",
    "print(\"\\nIncome DataFrame:\")\n",
    "print(income_df)\n",
    "\n",
    "inner_merged = pd.merge(population_df, income_df, on='City', how='inner')\n",
    "print(\"\\nInner Join Result (only matching cities):\")\n",
    "print(inner_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Left join\n",
    "left_merged = pd.merge(population_df, income_df, on='City', how='left')\n",
    "print(\"Left Join Result (all population cities):\")\n",
    "print(left_merged)\n",
    "\n",
    "# Fill missing income\n",
    "left_merged['Avg_Income'] = left_merged['Avg_Income'].fillna(0)\n",
    "print(\"\\nAfter filling missing values:\")\n",
    "print(left_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Concatenate\n",
    "luzon_data = pd.DataFrame({\n",
    "    'Region': ['NCR', 'Region III', 'Region IV-A'],\n",
    "    'Population': [13484462, 12422172, 16195042],\n",
    "    'Island_Group': ['Luzon', 'Luzon', 'Luzon']\n",
    "})\n",
    "\n",
    "visayas_data = pd.DataFrame({\n",
    "    'Region': ['Region VI', 'Region VII', 'Region VIII'],\n",
    "    'Population': [7954723, 8081988, 4547150],\n",
    "    'Island_Group': ['Visayas', 'Visayas', 'Visayas']\n",
    "})\n",
    "\n",
    "combined_df = pd.concat([luzon_data, visayas_data], ignore_index=False)\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Transformations - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Creating new columns\n",
    "city_df = pd.DataFrame({\n",
    "    'City': ['Manila', 'Quezon City', 'Caloocan', 'Davao'],\n",
    "    'Population': [1780000, 2960000, 1660000, 1780000],\n",
    "    'Area_km2': [42.88, 161.11, 53.33, 2443.61]\n",
    "})\n",
    "\n",
    "# Population density\n",
    "city_df['Density'] = city_df['Population'] / city_df['Area_km2']\n",
    "\n",
    "# Categorize by population\n",
    "def categorize_population(pop):\n",
    "    if pop > 2000000:\n",
    "        return 'Large'\n",
    "    elif pop >= 1000000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Small'\n",
    "\n",
    "city_df['Size_Category'] = city_df['Population'].apply(categorize_population)\n",
    "\n",
    "print(\"DataFrame with new columns:\")\n",
    "print(city_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Grouping and aggregation\n",
    "gdp_data = pd.DataFrame({\n",
    "    'Region': ['NCR', 'NCR', 'NCR', 'Region VII', 'Region VII', 'Region XI', 'Region XI'],\n",
    "    'Year': [2020, 2021, 2022, 2020, 2021, 2020, 2021],\n",
    "    'GDP_Billion': [6200, 6450, 6800, 1100, 1150, 850, 900]\n",
    "})\n",
    "\n",
    "print(\"GDP Data:\")\n",
    "print(gdp_data)\n",
    "\n",
    "# Average GDP per region\n",
    "avg_gdp = gdp_data.groupby('Region')['GDP_Billion'].mean()\n",
    "print(\"\\nAverage GDP by Region:\")\n",
    "print(avg_gdp)\n",
    "\n",
    "# Total GDP per region\n",
    "total_gdp = gdp_data.groupby('Region')['GDP_Billion'].sum()\n",
    "print(\"\\nTotal GDP by Region:\")\n",
    "print(total_gdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Reflection Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Answer to Question 1: Missing Data Strategy\n",
    "\n",
    "**When to drop:**\n",
    "- Very small percentage of missing data (< 5%)\n",
    "- Missing data is random and not systematic\n",
    "- You have enough data remaining after dropping\n",
    "\n",
    "**When to fill:**\n",
    "- Large percentage of missing data\n",
    "- Pattern to missingness (systematic)\n",
    "- Cannot afford to lose rows\n",
    "\n",
    "**Trade-offs:**\n",
    "- **Dropping:** Lose information but maintain data quality\n",
    "- **Filling:** Keep all data but may introduce bias or inaccuracy\n",
    "\n",
    "**Filling methods:**\n",
    "- Mean/median: Good for numerical data without outliers\n",
    "- Forward/backward fill: Good for time series\n",
    "- Mode: Good for categorical data\n",
    "- Prediction: Use ML models to predict missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Answer to Question 2: Data Cleaning Impact\n",
    "\n",
    "**Why crucial:**\n",
    "- Ensures accuracy of analysis results\n",
    "- Prevents errors in calculations\n",
    "- Makes data consistent and comparable\n",
    "- Improves efficiency of analysis\n",
    "\n",
    "**Example of wrong conclusions:**\n",
    "- **Scenario:** Student data with '23,000' stored as string\n",
    "- **Without cleaning:** Sum would fail or skip the value\n",
    "- **Result:** Total enrollment calculated as 17,000 instead of 40,000\n",
    "- **Impact:** University underestimates resources needed\n",
    "\n",
    "**Other examples:**\n",
    "- Duplicate entries inflate counts\n",
    "- Inconsistent capitalization causes grouping errors\n",
    "- Mixed date formats lead to sorting problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Answer to Question 3: Merging Strategies\n",
    "\n",
    "**Inner Join:**\n",
    "- **What:** Only rows with matching keys in both tables\n",
    "- **When:** You only want complete records where data exists in both sources\n",
    "- **Example:** Matching student records with grades (only students who took exams)\n",
    "\n",
    "**Left Join:**\n",
    "- **What:** All rows from left table, matching from right\n",
    "- **When:** Keep all records from primary table, add supplementary info where available\n",
    "- **Example:** All students with their grades (including students who haven't taken exams)\n",
    "\n",
    "**Outer Join (Full):**\n",
    "- **What:** All rows from both tables\n",
    "- **When:** Need complete picture from both sources\n",
    "- **Example:** All students OR grades (catch students with no grades and grades with no student match)\n",
    "\n",
    "**Right Join:**\n",
    "- Same as left but reversed (rarely used, just flip tables and use left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Solution Complete!\n",
    "\n",
    "**Key Concepts Demonstrated:**\n",
    "1. âœ“ Identifying and handling missing data with `.isnull()`, `.fillna()`\n",
    "2. âœ“ Cleaning strings with `.str` methods\n",
    "3. âœ“ Converting data types with `pd.to_numeric()`\n",
    "4. âœ“ Removing duplicates with `.drop_duplicates()`\n",
    "5. âœ“ Merging with `pd.merge()` (inner, left, outer)\n",
    "6. âœ“ Concatenating with `pd.concat()`\n",
    "7. âœ“ Creating derived columns with calculations and `.apply()`\n",
    "8. âœ“ Grouping and aggregation with `.groupby()`\n",
    "\n",
    "**Next Steps:**\n",
    "- Try these techniques on real Philippine datasets (PSA OpenSTAT)\n",
    "- Explore pivot tables and reshaping\n",
    "- Learn advanced merging (multiple keys, fuzzy matching)\n",
    "- Practice with datetime cleaning\n",
    "\n",
    "---\n",
    "\n",
    "*CMSC 178DA - Data Analytics | University of the Philippines Cebu*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}